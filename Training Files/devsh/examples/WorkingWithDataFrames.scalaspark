// Upload  to HDFS
// $ hdfs dfs -put $DEVSH/examples/example-data/people.csv
// $ hdfs dfs -put $DEVSH/examples/example-data/people-no-header.csv
// $ hdfs dfs -put $DEVSH/examples/example-data/users.json

// Start Scala shell: 
// $ spark2-shell

// Create a DF from data in memory
val myData = List(("Josiah","Bartlett"),("Harry","Potter"))
val myDF = spark.createDataFrame(myData)
myDF.show

// Write data to a Hive metastore table called mydata
// $ hdfs dfs -mkdir /loudacre/mydata
myDF.write.mode("append"). option("path","/loudacre/mydata").saveAsTable("my_table")

// Write data as Parquet files in the mydata directory
myDF.write.mode("overwrite").save("mydata")

// Write data as JSON files in the mydata directory
myDF.write.mode("overwrite").json("mydata")

// Display schema
myDF.printSchema

// Inferring the Schema of a CSV File (No Header)
spark.read.option("inferSchema","true").csv("people-no-header.csv").printSchema

// Example: Inferring the Schema of a CSV File (with Header)
spark.read.option("inferSchema","true"). option("header","true").csv("people.csv").printSchema

// Defining a Schema Programmatically 
import org.apache.spark.sql.types._

val columnsList = List(
  StructField("pcode", StringType),
  StructField("lastName", StringType),
  StructField("firstName", StringType),
  StructField("age", IntegerType))

val peopleSchema = StructType(columnsList)

val peopleDF = spark.read.option("header","true").schema(peopleSchema).csv("people.csv")
peopleDF.printSchema

// Eager and lazy execution
val usersDF = spark.read.json("users.json")
val nameAgeDF = usersDF.select("name","age")
nameAgeDF.show