// Create a DataFrame based on the Hive accounts table
val accountsDF = spark.read.table("accounts")

// Perform a simple query using both syntaxes for column reference
accountsDF. select(accountsDF("first_name")).show
accountsDF.select($"first_name").show

// Create a column reference referring to the first_name column in the accounts table
val fnCol = accountsDF("first_name")

// Create and use a column expression to select users named Lucy in the first_name column
val lucyCol = (fnCol === "Lucy")
accountsDF.select($"first_name",$"last_name",lucyCol).show
accountsDF.where(lucyCol).show(5)
accountsDF.where(fnCol === "Lucy").show(5)

accountsDF.select($"city", $"state",$"phone_number".substr(1,3)).show(5)
accountsDF.select($"city", $"state",$"phone_number".substr(1,3).alias("area_code")).show(5)

accountsDF.where($"first_name".substr(1,2) === $"last_name".substr(1,2)).select("first_name","last_name").show(5)

accountsDF.groupBy("last_name").count.show(5)
accountsDF.groupBy("last_name","first_name").count.show(5)

val baseDF = spark.read.parquet("/loudacre/base_stations.parquet")

accountsDF.select("acct_num","first_name","last_name","zipcode").join(baseDF, $"zip" === $"zipcode").show()


// ------ Count active devices ---------

// Load accountdevice data to HDFS in another terminal window
// $ hdfs dfs -put $DEVDATA/accountdevice/ /loudacre/

// Create a DataFrame from the account device data
val accountDeviceDF = spark.read.option("header","true").option("inferSchema","true").csv("/loudacre/accountdevice")

// Create a DataFrame with only active accounts
val activeAccountsDF = accountsDF.where(accountsDF("acct_close_dt").isNull)

// Create a DataFrame with a device model IDs for only devices used by active accounts
val activeAcctDevsDF =  activeAccountsDF.join(accountDeviceDF,activeAccountsDF("acct_num") === accountDeviceDF("account_id")).select("device_id")

// Sum up the total number of each device model 
val sumDevicesDF = activeAcctDevsDF.groupBy("device_id").count().withColumnRenamed("count","active_num")

// Order by count
val orderDevicesDF = sumDevicesDF.orderBy($"active_num".desc)

// create a DataFrame based on the devices.json file
val devDF = spark.read.json("/loudacre/devices.json")

// Join the list of device model totals with the list of devices
// to get the make and model for each device
val joinDevicesDF = orderDevicesDF.join(devDF,orderDevicesDF("device_id") === devDF("devnum"))

// Write out the data with the correct columns
// use overwrite mode so solution can be run multiple times
joinDevicesDF.select("device_id","make","model","active_num").write.mode("overwrite").save("/loudacre/top_devices")

// Review exercise results
// $ parquet-tools head hdfs://master-1/loudacre/top_devices
